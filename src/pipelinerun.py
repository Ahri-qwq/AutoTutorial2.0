import os
import re
import time
from src.llm_client import LLMClient
from src.retriever import LocalRetriever  # æ–°å¢å¼•ç”¨

class AutoTutorialPipeline:
    def __init__(self, root_dir):
        self.root_dir = root_dir
        self.prompts_dir = os.path.join(root_dir, "prompts")
        self.llm = LLMClient()
        self.retriever = LocalRetriever()
        
        # === ç”ŸæˆåŸºäºæ—¶é—´æˆ³çš„è¿è¡Œç›®å½• ===
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        self.run_dir = os.path.join(root_dir, "data", "runs", f"{timestamp}")
        # åœ¨è¯¥è¿è¡Œç›®å½•ä¸‹åˆ›å»º processed å­ç›®å½•ï¼ˆç”¨äºå­˜æ”¾è¿‡ç¨‹æ–‡ä»¶ï¼‰
        self.processed_dir = os.path.join(self.run_dir, "processed")
        os.makedirs(self.processed_dir, exist_ok=True)
        print(f"[Init] æœ¬æ¬¡è¿è¡Œçš„å·¥ä½œç›®å½•: {self.run_dir}")
        print(f"[Init] ä¸­é—´æ–‡ä»¶å°†ä¿å­˜åœ¨: {self.processed_dir}")
        self.current_topic = ""
        self.current_special_instructions = ""

    def _load_prompt(self, filename):
        path = os.path.join(self.prompts_dir, filename)
        if os.path.exists(path):
            with open(path, 'r', encoding='utf-8') as f:
                return f.read()
        return ""

    def _fill_prompt(self, template, **kwargs):
        """æ™ºèƒ½å¡«å…… Promptï¼Œå¦‚æœæ¨¡æ¿é‡Œæ²¡æœ‰å ä½ç¬¦ï¼Œè‡ªåŠ¨è¿½åŠ åœ¨æœ«å°¾"""
        content = template
        context = kwargs.pop("CONTEXT", "")
        
        # 1. æ›¿æ¢æ ‡å‡†å ä½ç¬¦
        for k, v in kwargs.items():
            content = content.replace(f"{{{{{k}}}}}", str(v))
        
        # 2. å¤„ç†ä¸Šä¸‹æ–‡ (CONTEXT)
        if "{{CONTEXT}}" in content:
            content = content.replace("{{CONTEXT}}", context)
        elif context:
            # å¦‚æœæ¨¡æ¿é‡Œæ²¡å†™ {{CONTEXT}}ï¼Œæˆ‘ä»¬æ‰‹åŠ¨åŠ åœ¨æœ€å
            content += f"\n\n# å‚è€ƒèµ„æ–™åº“ (Knowledge Base)\nè¯·åŸºäºä»¥ä¸‹æ£€ç´¢åˆ°çš„èµ„æ–™è¿›è¡Œå›ç­”ï¼Œå¦‚æœèµ„æ–™ä¸è¶³ï¼Œè¯·ç»“åˆä½ çš„ä¸“ä¸šçŸ¥è¯†è¡¥å……ï¼š\n{context}"
            
        return content

    def run_step1(self, topic):
        """Step 1: çŸ¥è¯†é¢„ç ”"""
        self.current_topic = topic
        print(f"\n=== Step 1: çŸ¥è¯†é¢„ç ” (Topic: {topic}) ===")
        
        # 1. æ£€ç´¢
        retrieved_context = self.retriever.search(f"å…³äº {topic} çš„ç‰©ç†åŸç†ã€å‚æ•°è®¾ç½®å’Œè®¡ç®—æµç¨‹", top_k=8)
        
        # 2. åŠ è½½ Prompt
        prompt_tmpl = self._load_prompt("step1_enrich.txt")
        if not prompt_tmpl: return

        # 3. ç»„è£…
        final_prompt = self._fill_prompt(prompt_tmpl, TOPIC=topic, CONTEXT=retrieved_context)

        # 4. è°ƒç”¨ LLM
        print(f"[Agent] æ­£åœ¨åˆ†æ...")
        response = self.llm.chat(final_prompt)
        if not response: return

        # 5. ä¿å­˜
        output_path = os.path.join(self.processed_dir, "step1_enrichment.md")
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(response)
        print(f"[Success] çŸ¥è¯†é¢„ç ”å®Œæˆ: {output_path}")

    def run_step2(self):
        """Step 2: å¤§çº²è§„åˆ’"""
        print("\n=== Step 2: å¤§çº²è§„åˆ’ ===")
        
        step1_path = os.path.join(self.processed_dir, "step1_enrichment.md")
        if not os.path.exists(step1_path):
            print("[Error] è¯·å…ˆè¿è¡Œ Step 1")
            return
            
        with open(step1_path, 'r', encoding='utf-8') as f:
            background_info = f.read()

        prompt_tmpl = self._load_prompt("step2_outline.txt")
        if not prompt_tmpl: return

        # Step 2 ä¸éœ€è¦é¢å¤–æ£€ç´¢ï¼Œå› ä¸ºå®ƒä¾èµ– Step 1 çš„æ€»ç»“
        final_prompt = self._fill_prompt(
            prompt_tmpl, 
            BACKGROUND_INFO=background_info[:6000],
            TOPIC=self.current_topic
        )

        print("[Agent] æ­£åœ¨è®¾è®¡å¤§çº²...")
        response = self.llm.chat(final_prompt)
        if not response: return

        output_path = os.path.join(self.processed_dir, "step2_outline.md")
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(response)
        print(f"[Success] å¤§çº²å·²ç”Ÿæˆ: {output_path}")

    def run_step3(self):
        """Step 3: åˆ†ç« æ’°å†™"""
        print("\n=== Step 3: æŠ€æœ¯ç« èŠ‚æ’°å†™ ===")
        outline_path = os.path.join(self.processed_dir, "step2_outline.md")
        if not os.path.exists(outline_path):
            print("[Error] è¯·å…ˆè¿è¡Œ Step 2")
            return

        with open(outline_path, 'r', encoding='utf-8') as f:
            outline = f.read()

        # === æ–°å¢ï¼šæå–ç‰¹æ®ŠæŒ‡ä»¤ ===
        step1_path = os.path.join(self.processed_dir, "step1_enrichment.md")
        special_instructions = "æ— ç‰¹æ®ŠæŒ‡ä»¤ã€‚"
        if os.path.exists(step1_path):
            with open(step1_path, 'r', encoding='utf-8') as f:
                content = f.read()
                # ç®€å•æ­£åˆ™æå– "## 4. æ•™ç¨‹ç¼–å†™ç‰¹æ®ŠæŒ‡ä»¤" åçš„å†…å®¹
                match = re.search(r"## 4\. æ•™ç¨‹ç¼–å†™ç‰¹æ®ŠæŒ‡ä»¤(.*?)(##|\Z)", content, re.DOTALL)
                if match:
                    special_instructions = match.group(1).strip()
        # å°†ç‰¹æ®ŠæŒ‡ä»¤å­˜ä¸ºç±»å±æ€§ï¼Œä¾› _draft_chapter ä½¿ç”¨
        self.current_special_instructions = special_instructions

        # ç®€å•çš„åˆ‡åˆ†é€»è¾‘ï¼šæŒ‰HTMLæ³¨é‡Šæˆ–äºŒçº§æ ‡é¢˜åˆ‡åˆ†
        parts = outline.split("<!-- CHAPTER_START -->")
        if len(parts) < 2:
            # å…¼å®¹æ²¡æœ‰æ³¨é‡Šçš„æƒ…å†µ
            parts = outline.split("## ")
        
        # è·³è¿‡å‰è¨€
        for idx, chunk in enumerate(parts):
            if idx == 0: continue # è·³è¿‡å‰è¨€/Meta
            
            # æ¸…ç†å†…å®¹
            chunk = chunk.replace("CHAPTER_START -->", "").strip()
            if not chunk: continue
            if "##" not in chunk and not chunk.startswith("ç¬¬"): 
                chunk = "## " + chunk # è¡¥å›æ ‡é¢˜æ ‡è®°

            # æå–æ ‡é¢˜
            lines = chunk.split('\n')
            title = lines[0].replace("#", "").strip()
            
            self._draft_chapter(title, chunk)

    def _draft_chapter(self, title, outline_context):
        print(f"\n[Drafting] æ­£åœ¨æ’°å†™: {title} ...")
        
        # 1. é’ˆå¯¹æœ¬ç« æ ‡é¢˜è¿›è¡Œç²¾å‡†æ£€ç´¢
        # æ¯”å¦‚æ ‡é¢˜æ˜¯"èƒ½å¸¦è®¡ç®—"ï¼Œæˆ‘ä»¬ä¼šæœå‡ºå…·ä½“çš„ KPT, INPUT è®¾ç½®
        #retrieved_context = self.retriever.search(f"ABACUSæ•™ç¨‹: {title} çš„å…·ä½“å‚æ•°ã€è¾“å…¥æ–‡ä»¶ç¤ºä¾‹å’Œæ³¨æ„äº‹é¡¹", top_k=6)
        
        # ï¼ˆ1ï¼‰. å®½æ³›æ£€ç´¢ï¼šæœåŸç†
        theory_context = self.retriever.search(f"ABACUSåŸç† {title}", top_k=3)
        
        # ï¼ˆ2ï¼‰. ç²¾å‡†æ£€ç´¢ï¼šæœå‚æ•° (å¢åŠ  keyword æƒé‡)
        # å¼ºåˆ¶å¸¦ä¸Š "INPUT" æˆ– "å‚æ•°" å…³é”®è¯
        param_context = self.retriever.search(f"ABACUS INPUTå‚æ•°è®¾ç½® {title} ç¤ºä¾‹", top_k=5)
        
        # åˆå¹¶ä¸Šä¸‹æ–‡
        full_context = f"ã€ç†è®ºèƒŒæ™¯ã€‘\n{theory_context}\n\nã€å‚æ•°ä¸å®æ“ã€‘\n{param_context}"
        
        # 2. åŠ è½½ Prompt
        prompt_tmpl = self._load_prompt("step3_drafting.txt")
        if not prompt_tmpl: return

        # 3. å¡«å……
        final_prompt = self._fill_prompt(
            prompt_tmpl, 
            CHAPTER_TITLE=title, 
            CHAPTER_DESCRIPTION=outline_context,
            #CONTEXT=retrieved_context
            CONTEXT=full_context,
            SPECIAL_INSTRUCTIONS=getattr(self, 'current_special_instructions', '')
        )

        # 4. ç”Ÿæˆ
        content = self.llm.chat(final_prompt)
        if not content: return
        # === [ä¿®å¤] æ¸…ç† LLM å¯èƒ½é‡å¤ç”Ÿæˆçš„æ ‡é¢˜ ===
        content = re.sub(r'^#\s+.*?\n+', '', content.strip()).strip()
        # === æ–‡ä»¶åå¢åŠ æ•°å­—å‰ç¼€ ===
        # å°è¯•ä»æ ‡é¢˜ä¸­æå–ç« èŠ‚å· (ä¾‹å¦‚ "ç¬¬ä¸€ç« " -> "01", "3.1" -> "03_01")
        # ç®€å•çš„æ˜ å°„é€»è¾‘ï¼šç¬¬Xç«  -> 0X
        prefix = "99" # é»˜è®¤æ’åºé å
        chapter_map = {"ä¸€": "01", "äºŒ": "02", "ä¸‰": "03", "å››": "04", "äº”": "05", 
                       "å…­": "06", "ä¸ƒ": "07", "å…«": "08", "ä¹": "09", "å": "10"}
        
        match = re.search(r"ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)ç« ", title)
        if match:
            cn_num = match.group(1)
            prefix = chapter_map.get(cn_num, "99")


        # 5. ä¿å­˜
        safe_title = re.sub(r'[\\/*?:"<>|]', "", title).replace(" ", "_")
        # æ–°çš„æ–‡ä»¶åæ ¼å¼: 01_chapter_Title.md
        fname = f"{prefix}_chapter_{safe_title}.md"
        
        with open(os.path.join(self.processed_dir, fname), 'w', encoding='utf-8') as f:
            f.write(f"# {title}\n\n{content}")
        print(f" -> å·²ä¿å­˜: {fname}")
        
        time.sleep(2)

    def run_step4(self):
        """Step 4: æ™ºèƒ½ç»„è£…å…¨æ–‡ (å¢å¼ºç‰ˆï¼šå¸¦RAGçš„å‰è¨€ä¸é™„å½•)"""
        print("\n=== Step 4: å…¨æ–‡ç»„è£… (RAG Enhanced) ===")
        
        # 1. è¯»å–ç« èŠ‚
        chapter_files = sorted([f for f in os.listdir(self.processed_dir) if f.endswith(".md") and ("chapter_" in f or f.startswith("0"))])
        if not chapter_files:
            print(f"[Error] åœ¨ {self.processed_dir} æ²¡æœ‰æ‰¾åˆ°ç« èŠ‚æ–‡ä»¶ã€‚")
            return

        full_content = ""
        summaries = []
        for fname in chapter_files:
            path = os.path.join(self.processed_dir, fname)
            with open(path, 'r', encoding='utf-8') as f:
                content = f.read()
                full_content += content + "\n\n"
                summaries.append(f"[{fname}]: {content[:300]}...") # å¢åŠ æ‘˜è¦é•¿åº¦

        # 2. å®è§‚æ£€ç´¢ (Macro Retrieval)
        # æˆ‘ä»¬å»çŸ¥è¯†åº“é‡Œæœâ€œå­¦ä¹ è·¯çº¿â€ã€â€œç›¸å…³çŸ¥è¯†â€ã€â€œå‰ç½®åŸºç¡€â€
        print("[Retrieving] æ­£åœ¨æœç´¢å®è§‚èƒŒæ™¯çŸ¥è¯† (å­¦ä¹ è·¯çº¿/ç›¸å…³æ¦‚å¿µ)...")
        macro_query = f"{self.current_topic} çš„å‰ç½®çŸ¥è¯†ã€è¿›é˜¶å­¦ä¹ è·¯çº¿ã€ç›¸å…³è”çš„ç‰©ç†æ–¹æ³•ã€æ¨èé˜…è¯»æ–‡çŒ®"
        # æ£€ç´¢ top_k è®¾å¤§ä¸€ç‚¹ï¼Œè·å–æ›´å¤šå®½æ³›ä¿¡æ¯
        context = self.retriever.search(macro_query, top_k=6)

        # 3. è°ƒç”¨ Agent
        prompt_tmpl = self._load_prompt("step4_assembly.txt")
        if prompt_tmpl:
            print("[Agent] æ­£åœ¨æ’°å†™æ·±åº¦å‰è¨€ä¸é™„å½•...")
            
            # è¿™é‡Œæˆ‘ä»¬åˆ©ç”¨ _fill_prompt çš„è‡ªåŠ¨è¿½åŠ åŠŸèƒ½ï¼ŒæŠŠ context å¡è¿›å»
            final_prompt = self._fill_prompt(
                prompt_tmpl,
                CHAPTER_SUMMARIES="\n".join(summaries),
                CONTEXT=context  # æ³¨å…¥å®è§‚çŸ¥è¯†ï¼
            )
            
            response = self.llm.chat(final_prompt)
            
            # JSON è§£æé€»è¾‘ (ä¿æŒä¸å˜)
            import json
            book_title = f"ABACUS å®æˆ˜æ•™ç¨‹ï¼š{self.current_topic}"
            preface = ""
            appendix = ""
            
            try:
                clean_json = response.replace("```json", "").replace("```", "").strip()
                # å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
                start = clean_json.find("{")
                end = clean_json.rfind("}") + 1
                if start != -1 and end != -1:
                    json_str = clean_json[start:end]
                    data = json.loads(json_str)
                    book_title = data.get("book_title", book_title)
                    preface = data.get("preface_markdown", "")
                    appendix = data.get("appendix_markdown", "")
                else:
                    print("[Warn] JSON æ ¼å¼é”™è¯¯ï¼Œå°è¯•ç›´æ¥æå–ã€‚")
            except Exception as e:
                print(f"[Warn] è§£æå¤±è´¥ ({e})ï¼Œå°†ä¿ç•™åŸå§‹ç”Ÿæˆå†…å®¹ä½œä¸ºå‚è€ƒã€‚")

        # 4. æœ€ç»ˆæ‹¼æ¥
        final_doc = f"# {book_title}\n\n"
        if preface: final_doc += f"{preface}\n\n---\n\n"
        final_doc += full_content
        if appendix: final_doc += f"\n---\n\n{appendix}"

        # === æ ¸å¿ƒä¿®æ”¹ï¼šä¿å­˜åˆ°æœ¬æ¬¡è¿è¡Œçš„ç‹¬ç«‹ç›®å½• ===
        # æ–‡ä»¶åå¸¦ä¸Šä¸»é¢˜ï¼Œæ›´åŠ æ¸…æ™°
        safe_topic = re.sub(r'[\\/*?:"<>|]', "", self.current_topic).replace(" ", "_")[:30]
        output_filename = f"Final_Tutorial_{safe_topic}.md"
        # ç›´æ¥ä¿å­˜åœ¨ run_dir ä¸‹ (ä¸ processed åŒçº§)
        output_path = os.path.join(self.run_dir, output_filename)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(final_doc)

        print(f"[Success] å…¨æ–‡ç”Ÿæˆå®Œæ¯•ï¼")
        print(f"ğŸ“‚ æœ¬æ¬¡è¿è¡Œå½’æ¡£ä½ç½®: {self.run_dir}")
